# Docker Compose para APS Integration - Optimizado para múltiples entornos
version: '3.8'

x-common-variables: &common-variables
  POSTGRES_SERVER: postgres
  POSTGRES_USER: ${POSTGRES_USER:-aps_user}
  POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-aps_password}
  POSTGRES_DB: ${POSTGRES_DB:-aps_db}
  POSTGRES_PORT: 5432
  REDIS_HOST: redis
  REDIS_PORT: 6379
  REDIS_DB: 0
  SECRET_KEY: ${SECRET_KEY:-dev-secret-key-change-in-production}
  APS_CLIENT_ID: ${APS_CLIENT_ID}
  APS_CLIENT_SECRET: ${APS_CLIENT_SECRET}
  ENVIRONMENT: ${ENVIRONMENT:-development}

services:
  # ======================
  # Infrastructure Services
  # ======================
  
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: aps_postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-aps_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-aps_password}
      POSTGRES_DB: ${POSTGRES_DB:-aps_db}
      POSTGRES_INITDB_ARGS: "--encoding=UTF8 --locale=C"
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backend/scripts/init_db.sql:/docker-entrypoint-initdb.d/init_db.sql:ro
      - ./infra/postgres/postgresql.conf:/etc/postgresql/postgresql.conf:ro
    networks:
      - aps_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-aps_user} -d ${POSTGRES_DB:-aps_db}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"

  # Redis Cache and Session Store
  redis:
    image: redis:7-alpine
    container_name: aps_redis
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - redis_data:/data
      - ./infra/redis/redis.conf:/usr/local/etc/redis/redis.conf:ro
    networks:
      - aps_network
    restart: unless-stopped
    command: redis-server /usr/local/etc/redis/redis.conf
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 128M
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  # ======================
  # Application Services
  # ======================

  # Backend FastAPI
  backend:
    build: 
      context: ./backend
      dockerfile: Dockerfile
      target: ${BUILD_TARGET:-development}
      args:
        - BUILDKIT_INLINE_CACHE=1
    container_name: aps_backend
    environment:
      <<: *common-variables
      RUN_MIGRATIONS: "true"
      LOG_LEVEL: ${LOG_LEVEL:-info}
      WORKERS: ${BACKEND_WORKERS:-1}
    ports:
      - "${BACKEND_PORT:-8000}:8000"
    volumes:
      - ./backend:/app:${VOLUME_MODE:-rw}
      - uploads_data:/app/uploads
      - logs_data:/app/logs
    networks:
      - aps_network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"
    profiles:
      - dev
      - staging
      - production

  # Frontend React
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      target: ${FRONTEND_TARGET:-development}
      args:
        - REACT_APP_API_URL=${REACT_APP_API_URL:-http://localhost:8000}
        - REACT_APP_APS_CLIENT_ID=${APS_CLIENT_ID}
        - REACT_APP_ENVIRONMENT=${ENVIRONMENT:-development}
    container_name: aps_frontend
    ports:
      - "${FRONTEND_PORT:-3000}:${FRONTEND_INTERNAL_PORT:-3000}"
    volumes:
      - ./frontend:/app:${VOLUME_MODE:-rw}
      - frontend_node_modules:/app/node_modules
    networks:
      - aps_network
    depends_on:
      - backend
    restart: unless-stopped
    environment:
      - REACT_APP_API_URL=${REACT_APP_API_URL:-http://localhost:8000}
      - REACT_APP_APS_CLIENT_ID=${APS_CLIENT_ID}
      - REACT_APP_ENVIRONMENT=${ENVIRONMENT:-development}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:${FRONTEND_INTERNAL_PORT:-3000}/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"
    profiles:
      - dev
      - staging
      - production

  # ======================
  # Worker Services
  # ======================

  # Celery Worker para tareas asíncronas
  celery_worker:
    build: 
      context: ./backend
      dockerfile: Dockerfile
      target: ${BUILD_TARGET:-development}
    container_name: aps_celery_worker
    environment:
      <<: *common-variables
      CELERY_WORKER_CONCURRENCY: ${CELERY_CONCURRENCY:-4}
      CELERY_WORKER_LOGLEVEL: ${CELERY_LOG_LEVEL:-info}
    volumes:
      - ./backend:/app:${VOLUME_MODE:-rw}
      - uploads_data:/app/uploads
      - logs_data:/app/logs
    networks:
      - aps_network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    command: celery -A app.core.celery worker --loglevel=${CELERY_LOG_LEVEL:-info} --concurrency=${CELERY_CONCURRENCY:-4}
    healthcheck:
      test: ["CMD", "celery", "-A", "app.core.celery", "inspect", "ping"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"
    profiles:
      - dev
      - staging
      - production

  # Celery Beat Scheduler
  celery_beat:
    build: 
      context: ./backend
      dockerfile: Dockerfile
      target: ${BUILD_TARGET:-development}
    container_name: aps_celery_beat
    environment:
      <<: *common-variables
    volumes:
      - ./backend:/app:${VOLUME_MODE:-rw}
      - celery_beat_data:/app/celerybeat-schedule
      - logs_data:/app/logs
    networks:
      - aps_network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    command: celery -A app.core.celery beat --loglevel=${CELERY_LOG_LEVEL:-info} --schedule=/app/celerybeat-schedule/celerybeat-schedule
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 128M
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"
    profiles:
      - staging
      - production

  # Celery Flower Monitor
  celery_flower:
    build: 
      context: ./backend
      dockerfile: Dockerfile
      target: ${BUILD_TARGET:-development}
    container_name: aps_celery_flower
    environment:
      <<: *common-variables
      FLOWER_BASIC_AUTH: ${FLOWER_USER:-admin}:${FLOWER_PASSWORD:-admin}
    ports:
      - "${FLOWER_PORT:-5555}:5555"
    networks:
      - aps_network
    depends_on:
      redis:
        condition: service_healthy
      celery_worker:
        condition: service_started
    restart: unless-stopped
    command: celery -A app.core.celery flower --port=5555 --basic_auth=${FLOWER_USER:-admin}:${FLOWER_PASSWORD:-admin}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5555"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 64M
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"
    profiles:
      - dev
      - staging

  # ======================
  # Monitoring Services
  # ======================

  # Prometheus Metrics
  prometheus:
    image: prom/prometheus:latest
    container_name: aps_prometheus
    ports:
      - "${PROMETHEUS_PORT:-9090}:9090"
    volumes:
      - ./infra/monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./infra/monitoring/rules:/etc/prometheus/rules:ro
      - prometheus_data:/prometheus
    networks:
      - aps_network
    restart: unless-stopped
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=15d'
      - '--web.enable-lifecycle'
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
    profiles:
      - monitoring
      - staging
      - production

  # Grafana Dashboard
  grafana:
    image: grafana/grafana:latest
    container_name: aps_grafana
    ports:
      - "${GRAFANA_PORT:-3001}:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./infra/monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./infra/monitoring/grafana/datasources:/etc/grafana/provisioning/datasources:ro
    networks:
      - aps_network
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=grafana-piechart-panel
    depends_on:
      - prometheus
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f localhost:3000/api/health && echo 'ready'"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    profiles:
      - monitoring
      - staging
      - production

  # ======================
  # Production Services
  # ======================

  # Nginx Reverse Proxy y Load Balancer
  nginx:
    image: nginx:1.25-alpine
    container_name: aps_nginx
    ports:
      - "${NGINX_HTTP_PORT:-80}:80"
      - "${NGINX_HTTPS_PORT:-443}:443"
    volumes:
      - ./infra/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./infra/nginx/conf.d:/etc/nginx/conf.d:ro
      - ./infra/nginx/ssl:/etc/nginx/ssl:ro
      - nginx_logs:/var/log/nginx
    networks:
      - aps_network
    depends_on:
      - frontend
      - backend
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 64M
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"
    profiles:
      - production

# ======================
# Networks
# ======================
networks:
  aps_network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

# ======================
# Volumes
# ======================
volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  uploads_data:
    driver: local
  logs_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  nginx_logs:
    driver: local
  frontend_node_modules:
    driver: local
  celery_beat_data:
    driver: local